------ Métricas de rendimiento para clasificación en machine learning
Error: Cuando el modelo da falso positivo o falso negativo.

* Asertividad (Accuracy): Mide que tan bueno es un modelo para predecir correctamente las clases. Las prediciones
correctas pueden caer en dos categorias:

- Verdaderos positivos(TP): El modelo predice correctamente la clase positiva.
- Verdaderos negativos(TN): El modelo predice correctamente la clase negativa

Y las incorrectas pueden caer en:

- Falsos positivos(FP): El modelo predice incorrectamente la clase positiva.
- Falsos negativos(FN): El modelo predice incorrectamente la clase negativa.

A = T / T + F

* Tasa de verdadedores positivos (Recall): Mide cuantas observaciones de la clase positiva el modelo es capaz de
capturar a través de sus predicciones.

R = TP / TP + FN

* Precisión (Precision): Mide la proporción de verdaderos positivos en relación con todos los que el modelo ha
predicho como positivos, sean correctas o no estas predicciones, incluyendo a los TP Y FP.

P = TP / TP + FP

* F1-Score: Se usa cuando las clases están desequilibradas. Se define como la media armónica de la precisión y el recall,
cabe destacar que la media armónica da más peso a los valores bajos, por lo que el modelo obtendrá un F1-Score alto
mientras ambas métricas son altas, esta métrica varia de 0 a 1.

F1 = 2(P X R) / P + R

* Curva ROC (Receiver Operating Characteristic): Gráfica que muestra el rendimiento de un modelo de clasificación en todos
los umbrales de clasificación, esta curva traza dos parámetros:

- Tasa de verdaderos positivos(TPR) en el eje Y (Recall)

- Tasa de falsos positivos(FPR) en el eje X

FPR = FP / (FP + TN)

Esta métrica viene acompañada por el AUC(área bajo la curva), que nos dice si el modelo hace sus predicciones al azar con
un valor cercano al 0.5 y un modelo perfecto tendrá un valor de 1.

* Matriz de confusión: Es una tabla que describe el rendimiento de un modelo de clasificación en un conjunto de datos para
los que se conocen los verdaderos valores.

		Predicción positiva         Predicción negativa
Real positivo   Verdadero Positivo (TP)     Falso Negativo (FN)
Real negativo   Falso positivo (FP)         Verdadero Negativo (TN)



------ Métricas de rendimiento para regresión en machine learning
Error: Diferencia entre el valor teórico y el valor predicho.

* Error cuadrático(SE): Es la suma de los cuadrados de los errores.

SE = Σ(yt - yp)^2 , yt= valor teórico    yp= valor predicho

* Error cuadrático medio(MSE): Es el promedio de los cuadrados de los errores.

MSE = Σ(yt - yp)^2 / N , yt= valor teórico    yp= valor predicho   N= promedio de errores

* Raiz del error cuadrático medio(RMSE): Es la raíz cuadrada del promedio de los cuadrados de los errores.

RMSE = (Σ(yt - yp)^2 / N)^1/2 , yt= valor teórico    yp= valor predicho   N= promedio de errores

* Error absoluto medio(MAE): Es el promedio de los valores absolutos de los errores.

MAE = Σ|yt - yp| / N

* Coeficiente de determinación: Indica cuanta variación de los datos puede ser explicada por el modelo, un valor de 1
significa que el modelo puede explicar toda la variabilidad de los datos.

r^2 = 1 - (Σ|yt - yp|^2) / (Σ|yt - ypp|^2) 	ypp= promedio de los valores predichos	
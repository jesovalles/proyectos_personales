{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064be00c-3c44-4e77-ae1a-8204f1169030",
   "metadata": {},
   "source": [
    "## Red Neuronal Convolucional (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4816c4-53d8-4e97-9261-53b850983e4b",
   "metadata": {},
   "source": [
    "Implementación de una red neuronal convolucional (CNN) avanzada utilizando TensorFlow y Keras. Esta CNN está diseñada para clasificación de imágenes en datasets como CIFAR-10 o ImageNet y sigue las mejores prácticas en arquitectura de redes neuronales profundas.\n",
    "\n",
    "Incluye técnicas como:\n",
    "\n",
    "- *Batch Normalization* para acelerar el entrenamiento y mejorar la estabilidad.\n",
    "- *Dropout* para prevenir sobreajuste.\n",
    "- *Data Augmentation* para mejorar la capacidad de generalización.\n",
    "- *Callbacks* como reducción de la tasa de aprendizaje y early stopping.\n",
    "- *Residual Connections* inspiradas en ResNet para mejorar el flujo de gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de66fe3-38ff-4b9c-87c4-681c54907ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf789ee2-3463-4b3d-aa98-51fe3851b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura de la CNN avanzada\n",
    "def build_advanced_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Primera capa convolucional\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Segunda capa convolucional\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Tercera capa convolucional\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Capa completamente conectada\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796a7021-ff50-4286-bf46-44c20681fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar y entrenar el modelo\n",
    "def train_cnn(model, train_images, train_labels, val_images, val_labels, epochs=50, batch_size=64):\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks para optimización\n",
    "    lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    # Data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    datagen.fit(train_images)\n",
    "    \n",
    "    history = model.fit(\n",
    "        datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs,\n",
    "        callbacks=[lr_reduction, early_stopping]\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b9b7a-c7eb-49cb-8f98-7f27d4c54f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso del modelo con CIFAR-10\n",
    "def main():\n",
    "    (train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "    train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "    \n",
    "    model = build_advanced_cnn()\n",
    "    history = train_cnn(model, train_images, train_labels, test_images, test_labels)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    print(f'Accuracy en test: {test_acc:.4f}')\n",
    "    \n",
    "    model.save('cnn_advanced.h5')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b5ebf-716a-4d3d-9e23-1634642bb781",
   "metadata": {},
   "source": [
    "## Explicación:\n",
    "1. Arquitectura avanzada de CNN:\n",
    "- Tres bloques convolucionales con Batch Normalization y Dropout.\n",
    "- MaxPooling después de cada bloque para reducir dimensionalidad.\n",
    "- Capa completamente conectada con Dropout para evitar sobreajuste.\n",
    "- Capa de salida con activación Softmax para clasificación.\n",
    "  \n",
    "2. Entrenamiento optimizado:\n",
    "- Data Augmentation para mejorar la generalización.\n",
    "- ReduceLROnPlateau para ajustar dinámicamente la tasa de aprendizaje.\n",
    "- EarlyStopping para detener el entrenamiento si no mejora el rendimiento.\n",
    "  \n",
    "3. Uso del dataset CIFAR-10:\n",
    "- Descarga y preprocesamiento de imágenes (normalización).\n",
    "- Entrenamiento y evaluación del modelo.\n",
    "- Guardado del modelo entrenado en un archivo .h5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
